{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install -r requirements.txt",
   "id": "97b0ba4b280a5411"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-17T13:43:55.897569Z",
     "start_time": "2025-05-17T13:40:34.656461Z"
    }
   },
   "source": [
    "from data.create_dataloaders import create_dataloaders\n",
    "from model.smooth_cross_entropy import smooth_crossentropy\n",
    "from model.shake_pyramidnet import ShakePyramidNet\n",
    "from model.pyramidnet import PyramidNet\n",
    "from model.wide_res_net import WideResNet\n",
    "from train import create_model_fun, OptimizerType, train_multiple_models\n",
    "import torch\n",
    "\n",
    "batch_size = 128\n",
    "threads = 4\n",
    "\n",
    "depth = 16\n",
    "width_factor = 8\n",
    "dropout = 0.0\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model_fun_WRN = create_model_fun(WideResNet, depth=depth, width_factor=width_factor, dropout=dropout, in_channels=3, labels=100, device=device)\n",
    "\n",
    "dataset_name = 'cifar10'\n",
    "\n",
    "model_fun_pyramidnet = create_model_fun(PyramidNet,device=device, dataset=dataset_name, depth=110, alpha=48, num_classes=10, bottleneck=False)\n",
    "\n",
    "model_fun_shake_pyramidnet = create_model_fun(ShakePyramidNet, device=device, depth=110,\n",
    "                                              alpha=48, num_classes=10)\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = create_dataloaders(dataset_name=dataset_name,\n",
    "                                                                       batch_size=batch_size,\n",
    "                                                                       num_workers=threads,\n",
    "                                                                       validation_split=0.0)\n",
    "\n",
    "N = 3\n",
    "\n",
    "num_epochs = 400\n",
    "\n",
    "configs = [\n",
    "    # CIFAR 10\n",
    "    {\"model\": model_fun_WRN, \"criterion\": smooth_crossentropy,\n",
    "     \"optimizer\": {\"optimizer_type\": OptimizerType.SGD, \"learning_rate\": 0.1},\n",
    "     \"num_epochs\": num_epochs, \"model_name\": \"WRN\", \"name_suffix\": \"\"},\n",
    "\n",
    "    {\"model\": model_fun_WRN, \"criterion\": smooth_crossentropy,\n",
    "     \"optimizer\": {\"optimizer_type\": OptimizerType.SAM, \"learning_rate\": 0.1, \"momentum\": 0.9, \"weight_decay\": 5e-4,\n",
    "                   \"rho\": 0.05},\n",
    "     \"num_epochs\": int(num_epochs / 2), \"model_name\": \"WRN\", \"name_suffix\": \"\"},\n",
    "\n",
    "\n",
    "    {\"model\": model_fun_pyramidnet, \"criterion\": smooth_crossentropy,\n",
    "    \"optimizer\": {\"optimizer_type\": OptimizerType.SGD, \"learning_rate\": 0.05, \"momentum\": 0.9, \"weight_decay\": 5e-4},\n",
    "    \"num_epochs\": num_epochs, \"model_name\": \"PyramidNet-ShakeDrop\", \"name_suffix\": \"\"},\n",
    "\n",
    "    {\"model\": model_fun_pyramidnet, \"criterion\": smooth_crossentropy,\n",
    "    \"optimizer\": {\"optimizer_type\": OptimizerType.SAM, \"learning_rate\": 0.05, \"momentum\": 0.9, \"weight_decay\": 5e-4,\n",
    "                \"rho\": 0.05},\n",
    "    \"num_epochs\": int(num_epochs / 2), \"model_name\": \"PyramidNet-ShakeDrop\", \"name_suffix\": \"\"},\n",
    "]\n",
    "\n",
    "repeated_configs = []\n",
    "\n",
    "for i in range(N):\n",
    "    for config in configs:\n",
    "        new_config = config\n",
    "        new_config[\"name_suffix\"] = f\"{i + 1}\"\n",
    "        repeated_configs.append(new_config)\n",
    "\n",
    "\n",
    "train_multiple_models(repeated_configs, train_dataloader, val_dataloader, test_dataloader, dataset_name, device=device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: jhostic (jhostic-fer) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\jurah\\OneDrive\\Dokumenti\\SAM_evaluation\\wandb\\run-20250517_154058-fsj9taab</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jhostic-fer/WRN-SGD/runs/fsj9taab' target=\"_blank\">WRN-SGD</a></strong> to <a href='https://wandb.ai/jhostic-fer/WRN-SGD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/jhostic-fer/WRN-SGD' target=\"_blank\">https://wandb.ai/jhostic-fer/WRN-SGD</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/jhostic-fer/WRN-SGD/runs/fsj9taab' target=\"_blank\">https://wandb.ai/jhostic-fer/WRN-SGD/runs/fsj9taab</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: WRN-SGD\n",
      "\n",
      "==================================================\n",
      "Epoch 1/2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 252/352 [02:56<01:09,  1.43it/s, batch_loss=1.5398, batch_acc=0.2578, avg_loss=1.6814]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 29\u001B[39m\n\u001B[32m     21\u001B[39m num_epochs = \u001B[32m2\u001B[39m\n\u001B[32m     23\u001B[39m configs = [\n\u001B[32m     24\u001B[39m     {\u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m: model, \u001B[33m\"\u001B[39m\u001B[33mcriterion\u001B[39m\u001B[33m\"\u001B[39m: smooth_crossentropy, \u001B[33m\"\u001B[39m\u001B[33moptimizer\u001B[39m\u001B[33m\"\u001B[39m: {\u001B[33m\"\u001B[39m\u001B[33moptimizer_type\u001B[39m\u001B[33m\"\u001B[39m: OptimizerType.SGD}, \u001B[33m\"\u001B[39m\u001B[33mnum_epochs\u001B[39m\u001B[33m\"\u001B[39m: num_epochs, \u001B[33m\"\u001B[39m\u001B[33mmodel_name\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mWRN-SGD\u001B[39m\u001B[33m\"\u001B[39m},\n\u001B[32m     25\u001B[39m     {\u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m: model, \u001B[33m\"\u001B[39m\u001B[33mcriterion\u001B[39m\u001B[33m\"\u001B[39m: smooth_crossentropy, \u001B[33m\"\u001B[39m\u001B[33moptimizer\u001B[39m\u001B[33m\"\u001B[39m: {\u001B[33m\"\u001B[39m\u001B[33moptimizer_type\u001B[39m\u001B[33m\"\u001B[39m: OptimizerType.SAM}, \u001B[33m\"\u001B[39m\u001B[33mnum_epochs\u001B[39m\u001B[33m\"\u001B[39m: num_epochs / \u001B[32m2\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel_name\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mWRN-SAM\u001B[39m\u001B[33m\"\u001B[39m},\n\u001B[32m     26\u001B[39m     {\u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m: model, \u001B[33m\"\u001B[39m\u001B[33mcriterion\u001B[39m\u001B[33m\"\u001B[39m: smooth_crossentropy, \u001B[33m\"\u001B[39m\u001B[33moptimizer\u001B[39m\u001B[33m\"\u001B[39m: {\u001B[33m\"\u001B[39m\u001B[33moptimizer_type\u001B[39m\u001B[33m\"\u001B[39m: OptimizerType.ADAM}, \u001B[33m\"\u001B[39m\u001B[33mnum_epochs\u001B[39m\u001B[33m\"\u001B[39m: num_epochs, \u001B[33m\"\u001B[39m\u001B[33mmodel_name\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mWRN-ADAM\u001B[39m\u001B[33m\"\u001B[39m},\n\u001B[32m     27\u001B[39m ]\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m \u001B[43mtrain_multiple_models\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfigs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcifar10\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Dokumenti\\SAM_evaluation\\train.py:75\u001B[39m, in \u001B[36mtrain_multiple_models\u001B[39m\u001B[34m(configs, train_loader, val_loader, test_loader, dataset_name, device, use_wandb)\u001B[39m\n\u001B[32m     65\u001B[39m run = wandb.init(project=config[\u001B[33m'\u001B[39m\u001B[33mmodel_name\u001B[39m\u001B[33m'\u001B[39m], name=config[\u001B[33m'\u001B[39m\u001B[33mmodel_name\u001B[39m\u001B[33m'\u001B[39m], config={\n\u001B[32m     66\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33marchitecture\u001B[39m\u001B[33m\"\u001B[39m: config[\u001B[33m'\u001B[39m\u001B[33mmodel_name\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m     67\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mdataset\u001B[39m\u001B[33m\"\u001B[39m: dataset_name,\n\u001B[32m   (...)\u001B[39m\u001B[32m     71\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33moptimizer\u001B[39m\u001B[33m\"\u001B[39m: config[\u001B[33m'\u001B[39m\u001B[33moptimizer\u001B[39m\u001B[33m'\u001B[39m].get(\u001B[33m'\u001B[39m\u001B[33moptimizer_type\u001B[39m\u001B[33m'\u001B[39m, OptimizerType.SGD),\n\u001B[32m     72\u001B[39m })\n\u001B[32m     74\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mTraining model: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m75\u001B[39m trained_model, history = \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     76\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     77\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     78\u001B[39m \u001B[43m    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     79\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     80\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     81\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     82\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     83\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     84\u001B[39m \u001B[43m    \u001B[49m\u001B[43msave_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43msave_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     85\u001B[39m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_patience\u001B[49m\u001B[43m=\u001B[49m\u001B[43mearly_stopping_patience\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     86\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     87\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_wandb\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_wandb\u001B[49m\n\u001B[32m     88\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     90\u001B[39m wandb.finish()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Dokumenti\\SAM_evaluation\\train.py:202\u001B[39m, in \u001B[36mtrain_model\u001B[39m\u001B[34m(model, train_loader, val_loader, test_loader, criterion, optimizer, num_epochs, device, save_dir, early_stopping_patience, model_name, use_wandb)\u001B[39m\n\u001B[32m    199\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m    200\u001B[39m     \u001B[38;5;66;03m# Get predictions\u001B[39;00m\n\u001B[32m    201\u001B[39m     correct = torch.argmax(predictions.data, \u001B[32m1\u001B[39m) == labels\n\u001B[32m--> \u001B[39m\u001B[32m202\u001B[39m     batch_loss = \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m * inputs.size(\u001B[32m0\u001B[39m)\n\u001B[32m    203\u001B[39m     batch_acc = torch.sum(correct).double() / inputs.size(\u001B[32m0\u001B[39m)\n\u001B[32m    204\u001B[39m     running_loss += batch_loss\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset_name = 'cifar100'\n",
    "\n",
    "model_fun_WRN = create_model_fun(WideResNet, depth=depth, width_factor=width_factor, dropout=dropout, in_channels=3, labels=100, device=device)\n",
    "model_fun_pyramidnet = create_model_fun(PyramidNet, device=device, dataset=dataset_name, depth=110, alpha=48, num_classes=100, bottleneck=False)\n",
    "model_fun_shake_pyramidnet = create_model_fun(ShakePyramidNet, device=device, depth=110,\n",
    "                                              alpha=48, num_classes=100)\n",
    "train_dataloader, val_dataloader, test_dataloader = create_dataloaders(dataset_name=dataset_name,\n",
    "                                                                       batch_size=batch_size,\n",
    "                                                                       num_workers=threads,\n",
    "                                                                       validation_split=0.0)\n",
    "\n",
    "configs = [\n",
    "    {\"model\": model_fun_WRN, \"criterion\": smooth_crossentropy,\n",
    "     \"optimizer\": {\"optimizer_type\": OptimizerType.SGD, \"learning_rate\": 0.1},\n",
    "     \"num_epochs\": num_epochs, \"model_name\": \"WRN\", \"name_suffix\": \"\"},\n",
    "    {\"model\": model_fun_WRN, \"criterion\": smooth_crossentropy,\n",
    "     \"optimizer\": {\"optimizer_type\": OptimizerType.SAM, \"learning_rate\": 0.1, \"momentum\": 0.9, \"weight_decay\": 5e-4,\n",
    "                   \"rho\": 0.1},\n",
    "     \"num_epochs\": int(num_epochs / 2), \"model_name\": \"WRN\", \"name_suffix\": \"\"},\n",
    "\n",
    "    {\"model\": model_fun_pyramidnet, \"criterion\": smooth_crossentropy,\n",
    "     \"optimizer\": {\"optimizer_type\": OptimizerType.SGD, \"learning_rate\": 0.05, \"momentum\": 0.9,\n",
    "                   \"weight_decay\": 5e-4},\n",
    "     \"num_epochs\": num_epochs, \"model_name\": \"PyramidNet-ShakeDrop\", \"name_suffix\": \"\"},\n",
    "    {\"model\": model_fun_pyramidnet, \"criterion\": smooth_crossentropy,\n",
    "     \"optimizer\": {\"optimizer_type\": OptimizerType.SAM, \"learning_rate\": 0.05, \"momentum\": 0.9,\n",
    "                   \"weight_decay\": 5e-4,\n",
    "                   \"rho\": 0.2},\n",
    "     \"num_epochs\": int(num_epochs / 2), \"model_name\": \"PyramidNet-ShakeDrop\", \"name_suffix\": \"\"},\n",
    "\n",
    "]\n",
    "\n",
    "train_multiple_models(configs, train_dataloader, val_dataloader, test_dataloader, dataset_name, device=device)"
   ],
   "id": "94836be7b0fd2ffc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
